---
title: "Analysis of Callahan et al. 2017 Preterm Birth dataset"
author: "Benjamin J Callahan"
date: "7/13/2018"
output: html_document
---

Replication and refinement of a vaginal microbial signature of preterm birth in two racially distinct cohorts of US women. Callahan et al., 2017. https://doi.org/10.1073/pnas.1705899114

## Preliminaries

Load pregnancy data:
```{r load, warning=FALSE, message=FALSE}
#load packages
packages <- c("decontam", "ggplot2", "reshape2", "phyloseq", "dada2", "gridExtra")
sapply(packages, require, character.only = TRUE)

#settings
theme_set(theme_bw())
options(stringsAsFactors = FALSE)
path.in <- "~/DecontamManuscript/Analyses/CallahanPTB" # CHANGE ME
path.out <- "~/DecontamManuscript/Analyses/Figures" # CHANGE ME

#color palettes
cbbPalette <- c("#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7","#000000")
methodPalette <- c(Prevalence="turquoise3", Frequency="orangered1", Combined="darkorchid4")
prevalencePalette <- c("2" = "#edf8e9", "3-5" = "#bae4b3", "6-10" = "#74c476", "11+" = "#238b45")
```

Coincide stn with st:
```{r}
load(file.path(path.in, "preg_w_negs.rda"))
dfn$Negative <- dfn$BodySite %in% c("EC", "Mock", "NTC")
tab <- table(dfn$Run, dfn$Negative); tab # Drop Run04 as has no vaginal samples
dfn <- dfn[dfn$Run %in% rownames(tab)[rowSums(tab>0)==2],]
stn <- stn[rownames(dfn),]
ftn <- ftn[rownames(dfn),]
dfn$LibrarySize <- rowSums(stn)
ggplot(data=dfn, aes(x=BodySite, y=LibrarySize, color=BodySite)) + geom_jitter()
# Don't want to drop them though, since only doing it for positives. Not appropriate to do so in this context.
summary(rowSums(stn))
head(sort(rowSums(stn)),30) # Requiring at least 100 reads
dfn <- dfn[rowSums(stn)>=100,]
stn <- stn[rownames(stn),]
ftn <- ftn[rownames(ftn),]
#taxn <- assignTaxonomy(stn, "~/tax/silva_nr_v128_train_set.fa.gz", multithread=TRUE)
#saveRDS(taxn, file.path(path.in, "taxn.rds"))
taxn <- readRDS(file.path(path.in, "taxn.rds"))
```

Add quantitation data:
```{r}
dfq <- read.csv(file.path(path.in, "DNA_quant_IL2_3_5-9_forBen_20170507.csv"), header=TRUE, stringsAsFactors = FALSE)
dfq <- dfq[match(rownames(dfn), dfq$specimen.barcode),]
identical(dfq$specimen.barcode, rownames(dfn)) # TRUE
dfn$Concentration <- dfq$ng.ul
```

Make phyloseq object:
```{r}
psn <- phyloseq(otu_table(ftn, taxa_are_rows=FALSE), sample_data(dfn), tax_table(taxn))
psnprev <- transform_sample_counts(psn, function(x) ifelse(x>0, 1, 0))
psn
```

## Identify contaminants

Calculate decontam scores using the frequency, prevalence and combined methods.
```{r}
fdf <- isContaminant(psn, conc="Concentration", method="frequency", batch="Run", normalize=FALSE)
pdf <- isContaminant(psn, neg="Negative", method="prevalence", batch="Run", normalize=FALSE)
cdf <- isContaminant(psn, conc="Concentration", neg="Negative", method="combined", batch="Run", normalize=FALSE)
contamdf <- rbind(cbind(fdf, Method="Frequency"), cbind(pdf, Method="Prevalence"), cbind(cdf, Method="Combined"))
prev <- rep(taxa_sums(psnprev), times=3)
contamdf$Prevalence <- cut(prev, c(0, 2, 5, 10, 9999), labels=c("2", "3-5", "6-10", "11+"))
```

Plot histogram of scores.
```{r}
histo <- ggplot(data=contamdf, aes(x=p, fill=Prevalence)) + 
  scale_fill_manual(values=prevalencePalette) +
  geom_histogram(binwidth=0.01) + 
  labs(x = 'decontam Score', y='Number ASVs') + 
  facet_wrap(~Method)
histo
ggsave(file.path(path.out, "PTB_Score_Histogram.pdf"), histo, width=7, height=2.6, units="in", useDingbats=FALSE)
ggsave(file.path(path.out, "PTB_Score_Histogram.png"), histo, width=7, height=2.6, units="in")
```

The contaminant mode is quite clear in the combined histogram. At the 0.01-0.02 bin it starts to rise above the flat distribution, and then jumps dramatically in the 0.00-0.01 bin. That jump is almost entirely supported by high prevalence taxa for which we are most confident. The combined method also has the cleanest distribution. From this, a clear choice for a classification threshold for the combined method is P* = 0.01 (although the other methods could certainly be used as well).

Double-check threshold choice via a q-q plot.
```{r}
plot(sort(runif(sum(!is.na(cdf$p)))), sort(cdf$p), log="xy")
abline(0,1,col="red")
```

Yep, the (strong) deviation occurs at about 0.01.

## Compare Frequency and Prevalence methods

Let's look at the consistency between frequency and prevalence scores. This makes sense to do on a run-by-run basis (where raw scores are calculated) but also after choosing the score for overall classification (min by default).

```{r}
runs <- unique(dfn$Run)
# Frequency
fdf.run <- lapply(runs, function(run) {
  ps <- prune_samples(sample_data(psn)$Run == run, psn)
  df <- isContaminant(ps, conc="Concentration", method="frequency", normalize=FALSE)
  df <- cbind(df, Run = run)
  df
})
fdf.run <- do.call(rbind, fdf.run)
# Prevalence
pdf.run <- lapply(runs, function(run) {
  ps <- prune_samples(sample_data(psn)$Run == run, psn)
  df <- isContaminant(ps, neg="Negative", method="prevalence", normalize=FALSE)
  df <- cbind(df, Run = run)
  df
})
pdf.run <- do.call(rbind, pdf.run)
```

Density plot from per-batch scores:
```{r}
densdf <- data.frame(Sequence=rownames(fdf.run), Frequency=fdf.run$freq, Prevalence=fdf.run$prev, Run=fdf.run$Run,
                     P.Frequency=fdf.run$p, P.Prevalence=pdf.run$p)
dens <- ggplot(data=densdf, aes(x=P.Frequency, y=P.Prevalence, size=Frequency))
dens <- dens + geom_bin2d() + scale_fill_gradient(low="white", high="black") + theme(panel.grid=element_blank())
dens <- dens + labs(x = 'Score (Frequency)', y='Score (Prevalence)') + guides(size=FALSE)
dens <- dens + theme(aspect.ratio=1)
dens
```

Good agreement between the methods. 
*The warning is due to NA scores assigned when ASVs are present in less than two samples in a run.*

Density plot from overall scores (minimum across batches):
```{r, warning=FALSE}
densdf.tot <- data.frame(Sequence=rownames(fdf), Frequency=fdf$freq, Prevalence=fdf$prev,
                         P.Frequency=fdf$p, P.Prevalence=pdf$p)
dens.tot <- ggplot(data=densdf.tot, aes(x=P.Frequency, y=P.Prevalence, size=Frequency))
dens.tot <- dens.tot + geom_bin2d() + scale_fill_gradient(low="white", high="black") + theme(panel.grid=element_blank())
dens.tot <- dens.tot + labs(x = 'Score (Frequency)', y='Score (Prevalence)') + guides(size=FALSE)
dens <- dens + theme(aspect.ratio=1)
dens.tot
ggsave(file.path(path.out, "PTB_Score_Density.pdf"), dens.tot, width=4, height=2.8, units="in", useDingbats=FALSE)
ggsave(file.path(path.out, "PTB_Score_Density.png"), dens.tot, width=4, height=2.8, units="in")
```
Very good agreement between the methods. The concentration at 0.5/0.5 is due to that being the uninformative score, that will be assigned as the minimum for many true ASVs that were minimally present in some batch.

## Revisit Exploratory Associations

This code was derived from the analysis workflows associated with Callahan & Digiluio et al. 2017.

Make a subject data.frame with the average frequencies for all genera from the processed data used in the manuscript:
```{r}
load(file.path(path.in, "processed.rda"))
subdf <- df[!duplicated(df$SubjectID),c("SubjectID", "Cohort", "Race", "preterm", "Outcome")]
subdf$Outcome <- factor(subdf$Outcome, levels=c("Preterm","Term"))
for(sq in rownames(tax)) {
  subdf[,sq] <- tapply(ft[,sq], df$SubjectID, mean)[subdf$SubjectID]
}
```

Test the association of the average gestational frequency of each amplicon sequence variant (ASV) with PTB:
```{r}
sqs <- rownames(tax)
scores.uab <- rep(1.0, nrow(tax))
scores.stan <- rep(1.0, nrow(tax))
names(scores.stan) <- sqs; names(scores.uab) <- sqs
for(sq in rownames(tax)) {
  scores.stan[sq] <- suppressWarnings(wilcox.test(subdf[subdf$Cohort %in% "Stanford" & subdf$preterm, sq],
                                 subdf[subdf$Cohort %in% "Stanford" & !subdf$preterm, sq], alternative="greater")$p.value)
  scores.uab[sq] <- suppressWarnings(wilcox.test(subdf[subdf$Cohort %in% "UAB" & subdf$preterm, sq],
                                subdf[subdf$Cohort %in% "UAB" & !subdf$preterm, sq], alternative="greater")$p.value)
}
taxdf <- data.frame(pStanford = scores.stan, pUAB = scores.uab, Genus=tax[, "Genus"])
taxdf$freqStanford <- apply(ft[df$Cohort %in% "Stanford",], 2, mean)
taxdf$freqUAB <- apply(ft[df$Cohort %in% "UAB",], 2, mean)
rownames(taxdf) <- sqs

taxdf$Joint <- pchisq(-2*log(taxdf$pStanford * taxdf$pUAB), df=4, lower.tail=FALSE)
taxdf$Sig <- p.adjust(taxdf$Joint, method="BH") < 0.1
taxdf$Freq <- (taxdf$freqStanford + taxdf$freqUAB)/2
sum(p.adjust(scores.stan, method="BH")<0.1); sum(p.adjust(scores.uab, method="BH")<0.1)
```

Propagate the decontam scores to the exploratory analysis data.frame:
```{r}
rownames(cdf) <- colnames(stn)
taxdf$P.Contam <- cdf[rownames(taxdf), "p"]
```

Make exploratory plots (i.e. all variants) at the level of sequence variants, with points colored by their decontam score:
```{r}
taxdf$P.Contam[is.na(taxdf$P.Contam)] <- 0.5
taxdf$Category <- cut(taxdf$P.Contam, c(0, 1e-5, 0.01, 0.1, 1))
p.sv <- ggplot(data=taxdf, aes(x=pStanford, y=pUAB, color=Category, label=Genus)) + 
  geom_point() + 
  geom_text(data=taxdf[taxdf$P.Contam < 1e-6 & (taxdf$pUAB < 0.001 | taxdf$pStanford < 0.001),], color="magenta", vjust=-0.7) +
  scale_color_manual(values=c("(0,1e-05]"="magenta", "(1e-05,0.01]"="violetred2", "(0.01,0.1]"="grey", "(0.1,1]"="black"), name="decontam P") +
  scale_x_log10() + scale_y_log10() +
  theme_bw() + coord_fixed() + xlab("PTB Association P-value (Stanford)") + ylab("PTB Association P-value (UAB)")
p.sv
ggsave(file.path(path.out, "PTB_Fig6_Exploratory_ASVs.pdf"), p.sv, dev="pdf", width=6, height=4, units="in", useDingbats=FALSE)
```

The manuscript figure needs a bit of Illustrator manipulation of the text labels.

Clearly several of the ASVs significantly associated with PTB in the exploratory analysis were contaminants, as suggested in the original manuscript.

```{r}
sessionInfo()
```
